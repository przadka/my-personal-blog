---
author: Michał Prządka
pubDatetime: 2023-10-13T10:37:52.737Z
title: LLMs in My Engineering Workflow
postSlug: llms-in-engineering
featured: false
ogImage: /assets/human-robot-pp-og.png
description: Exploring the impact of LLMs in my daily engineering tasks. From refining code to understanding feedback, I explain how these AI tools have enhanced efficiency and productivity in my workflow over the past 6 months.
---

Many senior developers I've interacted with are hesitant about integrating GPT and LLMs into their engineering workflows. They may have tried Github Copilot or maybe even use it regularly. But at the same time, they voice concerns ranging from reliability issues and hallucinations to usability and cost. These are all valid points! Yet, I often sense that many, especially the veterans, stick to their known methods, finding it challenging to envision the benefits of these new tools.

Below, I've compiled various real-world instances of how I've leveraged LLMs in my engineering work over the past 6 months. These aren't just theoretical scenarios. They reflect actual moments where these tools helped me save time, enhance efficiency, and deliver added value to my clients. The versatility of this technology still baffles me, and the long list below clearly shows that versatility.

![Human and robot pair programming](/assets/human-robot-pp.png)

In my own work, I've used LLMs to:

- Review and refine my code.
- Ideate and explore various design decisions.
- Rapidly write code without getting bogged down by syntax.
- Write unit and integration tests.
- Understand feedback from senior developers without follow-up questions or clarifications.
- Translate code across different languages.
- Assist in debugging, especially in interpreting why tests fail and how to rectify them.
- Quickly understand an existing codebase.
- Analyze and understand data.
- Work with git, with simple and more advanced commands.
- Analyze code performance and devise metrics to gauge it.
- Write code directly from documentation, for example, when tapping into API endpoints.
- Navigate libraries unfamiliar to me.
- Use CLI tools with natural language rather than reading lengthy manuals.
- Rewrite my code, changing the functionality slightly.
- Rewrite an existing app to a different framework.
- Compose clear support emails to users encountering difficulties with the software I developed.
- Tweak configurations on my Linux setup (like enhancing the color scheme of my bash prompt for better productivity).
- Generate and review documentation.
- Write commit messages and comprehensive pull request descriptions.

It's hard to pick my favorite use-case from the list. I employ most of them regularly, even daily. What continually surprises me is ChatGPT's adeptness at articulating the thoughts of more experienced developers—especially when their insights elude my initial understanding. I felt very proud realizing that I no longer needed to seek further clarifications. I could get to work directly because ChatGPT explained something that was hidden from me initially, due of my lack of experience or context.

The potential applications of this technology extend far beyond my personal use-cases. A similar list can probably be created for other domains and other jobs. Again, it is the versatility of this new tool that is truly mesmerizing. I even hesitate to call it simply "a tool". What is it really? A new framework? A [compute platform](https://www.interconnects.ai/p/llms-are-computing-platforms)? Maybe an [operating system](https://twitter.com/karpathy/status/1707437820045062561)? We are still trying to figure it out.

Of course, neither GPT nor any LLM is a silver bullet that will replace good engineering skills or proper design decisions. You need to be extra careful not to grow overly dependent on them or blindly trust the outputs. But, if properly applied, they give you a huge leverage. I've noticed a significant performance boost in my own work, and I believe with more strategies and tools, there's potential for even greater advancements.
